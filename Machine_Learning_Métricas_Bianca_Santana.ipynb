{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/biancasantt/metricas_machine_learning-/blob/main/Machine_Learning_M%C3%A9tricas_Bianca_Santana.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Relatório de Métricas - Aprendizado de Máquina**\n"
      ],
      "metadata": {
        "id": "aTx12nBsYq3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autor: Bianca Santana da Silva\n"
      ],
      "metadata": {
        "id": "QBFkVFJ6Zd5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Métricas de Avaliação em Machine Learning - Importância:**\n",
        "\n",
        "As métricas de aprendizado de máquina desempenham uma função fundamental na avaliação de modelos, permitindo-nos mensurar e compreender o desempenho do modelo. Isso simplifica a comparação entre diversas abordagens e auxilia na escolha da melhor opção para resolver um problema específico."
      ],
      "metadata": {
        "id": "HBzw4y9ub-eF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**O QUE DEVERÁ SER ELABORADO?**\n",
        "\n",
        "Um módulo com métricas para avaliar algoritmos.\n",
        "\n",
        "\n",
        "***Classificação:***\n",
        "\n",
        "1. matriz_confusão\n",
        "2. acurácia\n",
        "3. macro f1\n",
        "4. f1, precisão e recall por classe\n",
        "5. mcc\n",
        "\n",
        "***Regressão:***\n",
        "\n",
        "1. mae\n",
        "2. mse\n",
        "3. rmse\n",
        "4. mape"
      ],
      "metadata": {
        "id": "TXIk1omgZmP6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Classificação***"
      ],
      "metadata": {
        "id": "0uoxFALWah3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Breve explicação:***\n",
        "\n",
        "Um modelo de classificação binária tem a finalidade de determinar a qual das duas classes possíveis uma nova observação pertence. Geralmente, essas duas classes são conhecidas como classe positiva (P) e classe negativa (N), e representam a presença ou ausência de um evento específico. Por exemplo, um caso típico seria a classificação de um paciente como portador (positivo) ou não portador (negativo) de uma determinada doença."
      ],
      "metadata": {
        "id": "3yqBTf5BbcPR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Desenvolvendo o trabalho:***\n",
        "\n",
        " Neste trabalho, abordaremos métricas destinadas à classificação binária, mas é importante destacar que essas métricas também podem ser estendidas para a classificação multiclasse.\n",
        "\n",
        "A avaliação de um modelo de classificação implica na comparação entre as classes previstas pelo modelo e as classes verdadeiras de cada exemplo. Todas as métricas de classificação compartilham o objetivo comum de quantificar o quão distante o modelo está da classificação perfeita, embora realizem essa avaliação de maneiras distintas."
      ],
      "metadata": {
        "id": "5MnaQe_3cxYt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importação de Bibliotecas:**\n",
        "   ```python\n",
        "   import numpy as np\n",
        "   ```\n",
        "   Esta linha importa a biblioteca NumPy para realizar cálculos numéricos eficientes."
      ],
      "metadata": {
        "id": "2100daQvgvY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importando a biblioteca numpy\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "JHNvpEjZdeYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Função - matriz_confusao**"
      ],
      "metadata": {
        "id": "FyE6n-2jeG4h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A matriz de confusão permite identificar facilmente os acertos e erros de classificação em cada classe, ajudando a determinar se o modelo favorece uma classe em detrimento da outra. Isso é crítico em situações onde erros têm consequências diferentes, como em diagnósticos médicos, onde um falso negativo pode ser mais grave do que um falso positivo.\n",
        "\n",
        "Rotular erroneamente um paciente como doente quando está saudável pode ser indesejado, pois pode resultar em tratamentos adicionais não necessários. Entretanto, o erro de falso negativo (rotular erroneamente um paciente como saudável quando está doente) é muito mais grave, já que pode levar à falta de tratamento necessário e potencialmente prejudicar a saúde do paciente.\n"
      ],
      "metadata": {
        "id": "JNwLisSWeNYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Função `matriz_confusao(gabarito, estimado)`:**\n",
        "   Esta função calcula a matriz de confusão, que é uma tabela que mostra o desempenho do modelo em termos de verdadeiros positivos (TP), falsos positivos (FP), verdadeiros negativos (TN) e falsos negativos (FN). A matriz é uma matriz 2x2, onde a primeira dimensão representa a classe real e a segunda dimensão representa a classe prevista."
      ],
      "metadata": {
        "id": "k5xhG-EugdhU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABK1_GJgYoOK"
      },
      "outputs": [],
      "source": [
        "def matriz_confusao(gabarito, estimado):\n",
        "    # Inicialize a matriz de confusão\n",
        "    matriz = np.zeros((2, 2), dtype=int)\n",
        "\n",
        "    for i in range(len(gabarito)):\n",
        "        verdadeiro = gabarito[i]\n",
        "        predito = estimado[i]\n",
        "        matriz[verdadeiro][predito] += 1\n",
        "\n",
        "    return matriz"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Função - acuracia**"
      ],
      "metadata": {
        "id": "KzA3QSPLg9BW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nos diz quantos de nossos exemplos foram de fato classificados corretamente, independente da classe. Por exemplo, se temos 100 observações e 90 delas foram classificados corretamente, nosso modelo possui uma acurácia de 90%."
      ],
      "metadata": {
        "id": "tqmEpCkhiIgR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "   **Função `acuracia(gabarito, estimado)`:**\n",
        "   Esta função calcula a acurácia do modelo, que é a proporção de predições corretas em relação ao total de predições. A acurácia é calculada como:\n",
        "\n",
        "$$\\text{Acurácia} = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
        "\n",
        "***observação relevante:***\n",
        "\n",
        "As variáveis TP, TN FP e FN, expressas na fórmula matemática, não existe no código implementado abaixo. Isso deve-se ao fato de que, aqui, estamos trabalhando diretamente sobre os valores da matriz confusão."
      ],
      "metadata": {
        "id": "5ZC5pvSMgSu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def acuracia(gabarito, estimado):\n",
        "    matriz = matriz_confusao(gabarito, estimado)\n",
        "    return (matriz[0][0] + matriz[1][1]) / np.sum(matriz)"
      ],
      "metadata": {
        "id": "wO4a_eNjd0er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Função - precision_recall_f1**"
      ],
      "metadata": {
        "id": "Rm0uoo37hIsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**precisão:** É a razão entre a quantidade de exemplos classificados corretamente como positivos e o total de exemplos classificados como positivos\n",
        "\n",
        "**Revocação (recall):** Ao contrário da precisão, dá maior ênfase para os erros por falso negativo. É a razão entre a quantidade de exemplos classificados corretamente como positivos e a quantidade de exemplos que são de fato positivos\n",
        "\n",
        "**Score F1:** Leva em consideração tanto a precisão quanto a revocação. Ela é definida pela média harmônica entre as duas"
      ],
      "metadata": {
        "id": "g3a6reQZiLI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "   **Função `precision_recall_f1(gabarito, estimado, classe)`:**\n",
        "   Esta função calcula a precisão, recall e F1-score para uma classe específica. A precisão é a proporção de verdadeiros positivos em relação a todos os positivos previstos:\n",
        "  \n",
        "  $$\\text{Precisão (Precision)} = \\frac{TP}{TP + FP}$$\n",
        "  \n",
        "  O recall é a proporção de verdadeiros positivos em relação a todos os verdadeiros positivos\n",
        "  \n",
        " $$\\text{Recall} = \\frac{TP}{TP + FN}$$\n",
        "  \n",
        "  O F1-score é uma média harmônica da precisão e do recall, ou seja:\n",
        "\n",
        "\n",
        "  $$\\text{Recall} = \\frac{TP}{TP + FN}$$\n",
        "\n"
      ],
      "metadata": {
        "id": "c-bobHU1hFe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_recall_f1(gabarito, estimado, classe):\n",
        "    tp = 0  # Verdadeiros positivos\n",
        "    fp = 0  # Falsos positivos\n",
        "    fn = 0  # Falsos negativos\n",
        "\n",
        "    for i in range(len(gabarito)):\n",
        "        if gabarito[i] == classe:\n",
        "            if estimado[i] == classe:\n",
        "                tp += 1\n",
        "            else:\n",
        "                fn += 1\n",
        "        elif estimado[i] == classe:\n",
        "            fp += 1\n",
        "\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    return precision, recall, f1"
      ],
      "metadata": {
        "id": "rrmzVWrgd35r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Função - macro_f1**"
      ],
      "metadata": {
        "id": "nia4jK3ZhRWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tT6vMmRhjS2V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Função `macro_f1(gabarito, estimado)`:**\n",
        "   Esta função calcula o F1-score macro, que é a média dos F1-scores para todas as classes. Isso é útil quando você tem várias classes e deseja uma métrica única para avaliar o desempenho do modelo.\n",
        "\n",
        "   $$F1 = \\frac{2 \\cdot \\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n"
      ],
      "metadata": {
        "id": "KGvLYYIChXRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def macro_f1(gabarito, estimado):\n",
        "    f1s = []\n",
        "    for classe in [0, 1]:\n",
        "        precision, recall, f1 = precision_recall_f1(gabarito, estimado, classe)\n",
        "        f1s.append(f1)\n",
        "\n",
        "    return sum(f1s) / len(f1s)"
      ],
      "metadata": {
        "id": "jvRMTHwad6ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Função - mcc**"
      ],
      "metadata": {
        "id": "urAt4gphhjPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Função `mcc(gabarito, estimado)`:**\n",
        "   Esta função calcula o coeficiente de correlação de Matthews (MCC), que é uma métrica que leva em consideração todos os elementos da matriz de confusão. É uma métrica que varia de -1 a 1, onde 1 indica uma predição perfeita, 0 indica uma predição aleatória e -1 indica uma inversão completa.\n",
        "\n",
        "   $$\\text{MCC} = \\frac{TP \\cdot TN - FP \\cdot FN}{\\sqrt{(TP + FP)(TP + FN)(TN + FP)(TN + FN)}}$$\n"
      ],
      "metadata": {
        "id": "hpluskEWhjx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mcc(gabarito, estimado):\n",
        "    matriz = matriz_confusao(gabarito, estimado)\n",
        "    tp = matriz[1][1]\n",
        "    tn = matriz[0][0]\n",
        "    fp = matriz[0][1]\n",
        "    fn = matriz[1][0]\n",
        "\n",
        "    denom = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
        "\n",
        "    if denom == 0:\n",
        "        return 0\n",
        "\n",
        "    return (tp * tn - fp * fn) / denom"
      ],
      "metadata": {
        "id": "LgWCWGQ7d8wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exemplo de Uso**"
      ],
      "metadata": {
        "id": "lR7rnyXEhrz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exemplo de Uso:**\n",
        "   O exemplo de uso no final do código mostra como chamar essas funções com um conjunto de dados de exemplo representado pelos vetores `gabarito` e `estimado`. Podemos substituir esses vetores, futuramente, pelos dados reais de um domínio."
      ],
      "metadata": {
        "id": "lZSSs1A1hrfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de uso:\n",
        "gabarito = [0, 1, 1, 0, 0, 1, 0, 1, 1, 0]\n",
        "estimado = [0, 1, 1, 0, 1, 1, 0, 0, 1, 0]\n",
        "\n",
        "print(\"========================================\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(matriz_confusao(gabarito, estimado))\n",
        "print(\"========================================\")\n",
        "\n",
        "print(\"Acurácia:\", acuracia(gabarito, estimado))\n",
        "print(\"Macro F1:\", macro_f1(gabarito, estimado))\n",
        "\n",
        "for classe in [0, 1]:\n",
        "    precision, recall, f1 = precision_recall_f1(gabarito, estimado, classe)\n",
        "    print(\"\")\n",
        "    print(f\"CLASSE {classe}:\")\n",
        "    print(\"Precisão:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1:\", f1)\n",
        "\n",
        "print(\"\\nMCC:\", mcc(gabarito, estimado))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkrGS_w_eALI",
        "outputId": "360d0e89-b543-4ca8-ee49-7327a324b1a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "Matriz de Confusão:\n",
            "[[4 1]\n",
            " [1 4]]\n",
            "========================================\n",
            "Acurácia: 0.8\n",
            "Macro F1: 0.8000000000000002\n",
            "\n",
            "CLASSE 0:\n",
            "Precisão: 0.8\n",
            "Recall: 0.8\n",
            "F1: 0.8000000000000002\n",
            "\n",
            "CLASSE 1:\n",
            "Precisão: 0.8\n",
            "Recall: 0.8\n",
            "F1: 0.8000000000000002\n",
            "\n",
            "MCC: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Análise da saída produzida pelo código em relação às métricas de avaliação:\n",
        "\n",
        "1. **Matriz de Confusão:**\n",
        "   - A matriz de confusão mostra como o modelo classificou os exemplos. Os elementos da diagonal representam as previsões corretas, enquanto os elementos fora da diagonal representam os erros. No exemplo, temos:\n",
        "     - Verdadeiros Positivos (TP): 4\n",
        "     - Falsos Positivos (FP): 1\n",
        "     - Verdadeiros Negativos (TN): 4\n",
        "     - Falsos Negativos (FN): 1\n",
        "\n",
        "2. **Acurácia (Accuracy):**\n",
        "   - A acurácia é uma medida geral do desempenho do modelo. No exemplo, a acurácia é de 80%, o que significa que o modelo acertou 80% das previsões.\n",
        "\n",
        "3. **F1-Score Macro:**\n",
        "   - O F1-Score macro é a média dos F1-scores para cada classe. Ele fornece uma visão geral do desempenho do modelo para todas as classes. No exemplo, o F1-Score macro é de aproximadamente 0,8.\n",
        "\n",
        "4. **Precisão, Recall e F1-Score por Classe:**\n",
        "   - As métricas de precisão, recall e F1-score são calculadas para cada classe (classe 0 e classe 1).\n",
        "   - Ambas as classes têm precisão, recall e F1-scores iguais a 0,8, o que indica um bom equilíbrio entre precisão e recall para ambas as classes.\n",
        "\n",
        "5. **Coeficiente de Correlação de Matthews (MCC):**\n",
        "   - O MCC é uma medida de correlação entre as previsões do modelo e os valores reais, levando em consideração todos os elementos da matriz de confusão. Quanto mais próximo de 1, melhor o modelo está em suas previsões. No exemplo, o MCC é de 0,6, o que indica uma correlação razoavelmente forte.\n",
        "\n",
        "Em resumo, com base na saída produzida, podemos concluir que o modelo tem um desempenho decente, com uma acurácia de 80% e um F1-Score macro de 0,8. As métricas de precisão, recall e F1-score por classe também são boas para ambas as classes. No entanto, uma análise mais aprofundada depende do contexto do problema e dos requisitos específicos de desempenho do modelo."
      ],
      "metadata": {
        "id": "sQ4pGK6HlVen"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***Regressão***"
      ],
      "metadata": {
        "id": "tGJrDiiDal83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As métricas discutidas anteriormente são usadas para avaliar problemas de classificação, nos quais o objetivo é prever a categoria de um ponto de dados desconhecido.\n",
        "\n",
        "No entanto, na área de Ciência de Dados, também é comum criar modelos de regressão, nos quais a tarefa envolve a previsão de uma variável numérica contínua. Exploraremos as principais métricas utilizadas para avaliar o desempenho de modelos de regressão."
      ],
      "metadata": {
        "id": "7akFUKcXpCLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora iremos calcular métricas de regressão em vez de métricas de classificação.\n",
        "\n",
        "Abaixo estão as implementações das métricas:\n",
        "\n",
        "1. MAE (Erro Médio Absoluto)\n",
        "2. MSE (Erro Médio Quadrático)\n",
        "3. RMSE (Raiz do Erro Médio Quadrático)\n",
        "4. MAPE (Erro Percentual Absoluto Médio)"
      ],
      "metadata": {
        "id": "8cJ06981oYA8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importação de Bibliotecas:**\n",
        "   ```python\n",
        "   import numpy as np\n",
        "   ```\n",
        "   Esta linha importa a biblioteca NumPy para realizar cálculos numéricos eficientes."
      ],
      "metadata": {
        "id": "23ndaRSinHoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "Pxiy8BZwmzoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Função - mae**"
      ],
      "metadata": {
        "id": "5oHX95gfnN7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Erro Absoluto Médio consiste na média das distâncias entre valores preditos e reais. Diferentemente do MSE e do RMSE, essa métrica não “pune” tão severamente os outliers do modelo.\n",
        "\n",
        "Essa medida apresenta valor mínimo 0 e não apresenta valor máximo.\n"
      ],
      "metadata": {
        "id": "u3WZ3EJHphUe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **MAE (Erro Médio Absoluto):**\n",
        "   - O MAE é calculado como a média das diferenças absolutas entre os valores reais e os valores previstos.\n",
        "\n",
        "   $$ MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| $$\n",
        "\n",
        "**legendando variáveis de acordo com a função matemática:**\n",
        "\n",
        "$$ gabarito = y $$\n",
        "$$ estimado = \\hat{y} $$"
      ],
      "metadata": {
        "id": "pSeukA6anSVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mae(gabarito, estimado):\n",
        "    return np.mean(np.abs(gabarito - estimado))\n"
      ],
      "metadata": {
        "id": "-Ad2C8kdm2XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Função - mse**"
      ],
      "metadata": {
        "id": "SKvBO7QWn7xw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A métrica mais amplamente empregada é o Erro Quadrático Médio (EQM), que envolve calcular a média dos quadrados dos erros de previsão. Em termos simples, é a diferença entre os valores previstos pelo modelo e os valores reais, elevados ao quadrado. Esse processo é aplicado a todos os pontos de dados, as somas são calculadas e, por fim, o resultado é dividido pelo número de previsões. Quanto maior o valor do EQM, pior o desempenho do modelo.\n",
        "\n",
        "É importante destacar que o valor mínimo possível para essa métrica é 0, e não há limite superior."
      ],
      "metadata": {
        "id": "EYDLWT3-plRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MSE (Erro Médio Quadrático):**\n",
        "   - O MSE é calculado como a média dos quadrados das diferenças entre os valores reais e os valores previstos.\n",
        "\n",
        "   $$ MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $$\n",
        "\n",
        "**legendando variáveis de acordo com a função matemática:**\n",
        "\n",
        "$$ gabarito = y $$\n",
        "$$ estimado = \\hat{y} $$"
      ],
      "metadata": {
        "id": "xeKkFVaxnpQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(gabarito, estimado):\n",
        "    return np.mean((gabarito - estimado) ** 2)"
      ],
      "metadata": {
        "id": "OOobw5Smm4KK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Função - rmse**"
      ],
      "metadata": {
        "id": "Vg15OKT_npaz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O RMSE entra como uma forma de melhorar a interpretabilidade da métrica, acertando a unidade. Entretanto, essa medida, assim como o MSE, penaliza predições muito distantes da real.\n"
      ],
      "metadata": {
        "id": "73MFcSRRp52J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RMSE (Raiz do Erro Médio Quadrático):**\n",
        "   - O RMSE é a raiz quadrada do MSE e fornece uma medida da dispersão dos erros em relação aos valores reais.\n",
        "\n",
        "$$ RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} $$\n",
        "\n",
        "**legendando variáveis de acordo com a função matemática:**\n",
        "\n",
        "$$ gabarito = y $$\n",
        "$$ estimado = \\hat{y} $$"
      ],
      "metadata": {
        "id": "UIrN5FMBns2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(gabarito, estimado):\n",
        "    return np.sqrt(mse(gabarito, estimado))"
      ],
      "metadata": {
        "id": "Kn6Cjbwlm67z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Função - mape**"
      ],
      "metadata": {
        "id": "_8tOqvyFoEqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em contraste com as métricas anteriores, essa medida exprime uma porcentagem, obtida através da divisão da diferença entre predito (ŷ) e real pelo valor real (y).\n",
        "\n",
        "Assim como o MSE e o MAE, quanto menor o valor, mais preciso seria o modelo de regressão."
      ],
      "metadata": {
        "id": "hUOPDv90qAxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **MAPE (Erro Percentual Absoluto Médio):**\n",
        "   - O MAPE é calculado como a média das diferenças percentuais absolutas entre os valores reais e os valores previstos. É multiplicado por 100 para expressar o resultado como uma porcentagem.\n",
        "\n",
        "   $$ MAPE = \\frac{1}{n} \\sum_{i=1}^{n} \\left|\\frac{y_i - \\hat{y}_i}{y_i}\\right| \\times 100\\% $$\n",
        "\n",
        "\n",
        "**legendando variáveis de acordo com a função matemática:**\n",
        "\n",
        "$$ gabarito = y $$\n",
        "$$ estimado = \\hat{y} $$\n"
      ],
      "metadata": {
        "id": "C7R_wBFxnsd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mape(gabarito, estimado):\n",
        "    return np.mean(np.abs((gabarito - estimado) / gabarito)) * 100"
      ],
      "metadata": {
        "id": "vEui2oPXm82T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exemplo de uso**"
      ],
      "metadata": {
        "id": "7vv0doaQoHCp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O exemplo de uso no final do código demonstra como calcular essas métricas para os vetores \"gabarito\" e \"estimado\". Futuramente, podemos substituir esses vetores pelos próprios dados de regressão de um determinado domínio."
      ],
      "metadata": {
        "id": "lpYB0JBvoKg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de uso:\n",
        "gabarito = np.array([10, 20, 30, 40, 50])\n",
        "estimado = np.array([12, 18, 28, 41, 49])\n",
        "\n",
        "print(\"MAE:\", mae(gabarito, estimado))\n",
        "print(\"MSE:\", mse(gabarito, estimado))\n",
        "print(\"RMSE:\", rmse(gabarito, estimado))\n",
        "print(\"MAPE:\", mape(gabarito, estimado))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4xpQ5j9m-5k",
        "outputId": "64e293ef-c5d6-49f4-8881-10fa9c0b9ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 1.6\n",
            "MSE: 2.8\n",
            "RMSE: 1.6733200530681511\n",
            "MAPE: 8.233333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Análise da saída produzida pelo código em relação às métricas de avaliação:\n",
        "\n",
        "1. **MAE (Erro Médio Absoluto):**\n",
        "   - O MAE é igual a 1.6. Isso significa que, em média, a diferença absoluta entre as previsões do modelo e os valores reais é de aproximadamente 1.6 unidades. Quanto menor o MAE, melhor o modelo em fazer previsões precisas.\n",
        "\n",
        "2. **MSE (Erro Médio Quadrático):**\n",
        "   - O MSE é igual a 2.8. Ele representa a média dos quadrados das diferenças entre as previsões e os valores reais. Quanto menor o MSE, mais próximas as previsões estão dos valores reais.\n",
        "\n",
        "3. **RMSE (Raiz do Erro Médio Quadrático):**\n",
        "   - O RMSE é aproximadamente 1.6733. É a raiz quadrada do MSE e fornece uma medida da dispersão dos erros. Quanto menor o RMSE, mais preciso é o modelo.\n",
        "\n",
        "4. **MAPE (Erro Percentual Absoluto Médio):**\n",
        "   - O MAPE é aproximadamente 8.2333%. Isso significa que, em média, as previsões do modelo têm um erro absoluto médio de cerca de 8.2333% em relação aos valores reais. O MAPE é uma métrica que expressa o erro percentual médio.\n",
        "\n",
        "Em resumo, com base nos resultados, o modelo parece ter um bom desempenho na previsão, com valores relativamente baixos de MAE, MSE e RMSE. Além disso, o MAPE indica que o erro percentual médio é moderado, mas ainda aceitável.\n",
        "\n",
        "No entanto, a interpretação dos resultados deve ser feita considerando o contexto específico do problema e as expectativas de precisão do modelo para a aplicação em questão."
      ],
      "metadata": {
        "id": "cLVkyeTzqP25"
      }
    }
  ]
}